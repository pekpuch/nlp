import pandas as pd
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import nltk
import matplotlib.pyplot as plt
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, classification_report
import pymorphy2
from pymystem3 import Mystem



train_df = pd.read_csv('dataset/train/train.tsv', sep='\t', header=None, names=['index_id', 'category', 'text'])
val_df = pd.read_csv('dataset/val/val.tsv', sep='\t', header=None, names=['index_id', 'category', 'text'])
test_df = pd.read_csv('dataset/test/test.tsv', sep='\t', header=None, names=['index_id', 'category', 'text'])


nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')


morph = pymorphy2.MorphAnalyzer()

stop_words = set(stopwords.words('russian'))

def preprocess_text(text):
    text = text.lower()  # Приведение к нижнему регистру
    text = re.sub(r'\W', ' ', text)  # Удаление всех неалфавитных символов
    words = text.split()  # Разбиение текста на слова
    lemmatized_words = [morph.parse(word)[0].normal_form for word in words]
    return ' '.join(lemmatized_words)


train_df['clean_text'] = train_df['text'].apply(preprocess_text)


train_df['clean_text']


#Рассчет TF-IDF
tfidf_results = {}

classes = train_df['category'].unique()  

for cls in classes:
    texts = train_df[train_df['category'] == cls]['clean_text']
    
    # Рассчет TF-IDF
    tfidf = TfidfVectorizer()
    X_tfidf = tfidf.fit_transform(texts).toarray()
    
    # Получаем слова 
    feature_names = tfidf.get_feature_names_out()
    
    tfidf_scores = X_tfidf.sum(axis=0)  # Суммируем TF-IDF 
    tfidf_results[cls] = {feature_names[i]: tfidf_scores[i] for i in range(len(feature_names))}



for cls, scores in tfidf_results.items():
    print(f"\nКласс: {cls}")
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    for word, score in sorted_scores[:10]:  # Выводим топ-10 слов по TF-IDF
        print(f"{word}: {score}")


tfidf = TfidfVectorizer()
train_X_tfidf = tfidf.fit_transform(train_df['clean_text']) # получаем таблицу, где столбцы - слова, строки - номер текста, значение - вес

scaler = StandardScaler()
train_X_scaled = scaler.fit_transform(train_X_tfidf.toarray()) # масштабируем, стандартизируем


pca = PCA(n_components=2)  # Понижаем размерность до 2D
train_X_pca = pca.fit_transform(train_X_scaled)


df_pca = pd.DataFrame(data=train_X_pca, columns=['Principal Component 1', 'Principal Component 2'])
df_pca['id'] = train_df['index_id']


df_pca


plt.figure(figsize=(8, 6))
plt.scatter(df_pca['Principal Component 1'], df_pca['Principal Component 2'], alpha=0.7)
for i, txt in enumerate(df_pca['id']):
    plt.annotate(txt, (df_pca['Principal Component 1'][i], df_pca['Principal Component 2'][i]))

plt.title('PCA of TF-IDF Features')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid()
plt.show()



vectorizer = CountVectorizer()
tfidf = TfidfVectorizer()
labels = open('dataset/data_rus_Cyrl_labels.txt').read().splitlines()


'''
MultinomialNB
Mystem, лемматизация
'''
model = MultinomialNB()

X_train_bow = vectorizer.fit_transform(train_df['clean_text'])
y_train = train_df['category']

X_test_bow = vectorizer.transform(test_df['text'])
y_test = test_df['category']

model.fit(X_train_bow, y_train)
y_pred = model.predict(X_test_bow)
print(classification_report(y_test, y_pred, target_names=labels)) 


'''
MultinomialNB
Датасет без обработки
'''

model = MultinomialNB()

X_train_bow = vectorizer.fit_transform(train_df['text'])
y_train = train_df['category']

X_test_bow = vectorizer.transform(test_df['text'])
y_test = test_df['category']

model.fit(X_train_bow, y_train)
y_pred = model.predict(X_test_bow)
print(classification_report(y_test, y_pred, target_names=labels)) 


'''
MultinomialNB
tfidf
Обработка
'''

model = MultinomialNB()

X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])
y_train = train_df['category']

X_test_tfidf = tfidf.transform(test_df['text'])
y_test = test_df['category']

model.fit(X_train_tfidf, y_train)
y_pred = model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred, target_names=labels)) 


'''
MultinomialNB
tfidf
без обработки
'''

model = MultinomialNB()

X_train_tfidf = tfidf.fit_transform(train_df['text'])
y_train = train_df['category']

X_test_tfidf = tfidf.transform(test_df['text'])
y_test = test_df['category']

model.fit(X_train_tfidf, y_train)
y_pred = model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred, target_names=labels)) 



