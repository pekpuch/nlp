{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9355d135-d154-4839-b16b-5e6bfd8210f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import pymorphy2\n",
    "from nlpaug.augmenter.word import SynonymAug\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0c6de64-a594-4916-a44b-c70dda71926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train/train.tsv', sep='\\t', header=None, names=['index_id', 'category', 'text'])\n",
    "val_df = pd.read_csv('dataset/val/val.tsv', sep='\\t', header=None, names=['index_id', 'category', 'text'])\n",
    "test_df = pd.read_csv('dataset/test/test.tsv', sep='\\t', header=None, names=['index_id', 'category', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc15559a-bc00-4363-a8c3-156942d35543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pekpuch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pekpuch/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pekpuch/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/pekpuch/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c27d7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # убираем мусорные слова\n",
    "\n",
    "# def remove_stop(text):\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\W', ' ', text)\n",
    "#     words = text.split()\n",
    "#     filtered_words = [word for word in words if word not in stop_words]\n",
    "#     return ' '.join(filtered_words)\n",
    "\n",
    "# train_df['text'] = train_df['text'].apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "769f9c4d-b92c-4bbb-be10-f82cabd72f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymorph\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "stop_words.add('это')\n",
    "stop_words.add('который')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Приведение к нижнему регистру\n",
    "    text = re.sub(r'\\W', ' ', text)  # Удаление всех неалфавитных символов\n",
    "    words = text.split()  # Разбиение текста на слова\n",
    "    lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
    "    filtered_words = [word for word in lemmatized_words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "train_df['clean_text'] = train_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4eb81e32-166d-4987-b927-330b4f925006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Класс: geography\n",
      "остров: 2.221010044437218\n",
      "миля: 1.7944958573032486\n",
      "река: 1.6890969657845956\n",
      "земля: 1.6277881084895456\n",
      "являться: 1.617737613366442\n",
      "км: 1.5206072804089168\n",
      "океан: 1.4055018165152247\n",
      "город: 1.1852191150330804\n",
      "луна: 1.1486271454613397\n",
      "большой: 1.130992553683145\n",
      "\n",
      "Класс: science/technology\n",
      "мочь: 4.388362740039852\n",
      "состоять: 2.793980528912469\n",
      "весь: 2.686870679656254\n",
      "атом: 2.591225422831247\n",
      "учёный: 2.490669956305439\n",
      "всё: 2.350185446291186\n",
      "солнце: 2.31022254241866\n",
      "человек: 2.260610163342592\n",
      "интернет: 2.243964335404921\n",
      "использовать: 2.214642996062189\n",
      "\n",
      "Класс: entertainment\n",
      "год: 1.4433356502846948\n",
      "хороший: 1.426908830436837\n",
      "шоу: 1.2687678826544586\n",
      "певец: 1.1306971706349844\n",
      "также: 1.121456098205432\n",
      "большинство: 1.1135116554598246\n",
      "мочь: 1.0500691974241712\n",
      "человек: 0.9883196645392918\n",
      "группа: 0.9761922511831229\n",
      "известный: 0.9680390165557149\n",
      "\n",
      "Класс: politics\n",
      "год: 3.698664134077792\n",
      "свой: 3.00199166529293\n",
      "правительство: 2.0982456866129695\n",
      "война: 2.08930765944435\n",
      "стать: 1.8003144817603478\n",
      "германия: 1.67198766254569\n",
      "время: 1.6597317960472944\n",
      "выборы: 1.60039405831766\n",
      "президент: 1.5216842293250914\n",
      "министр: 1.517557460667092\n",
      "\n",
      "Класс: health\n",
      "случай: 2.0519230923460734\n",
      "заболевание: 1.9024942138070482\n",
      "пострадать: 1.8632066506951501\n",
      "человек: 1.7950662147281213\n",
      "болезнь: 1.604665157788606\n",
      "медицинский: 1.404237313126996\n",
      "мочь: 1.3916783693341932\n",
      "вирус: 1.2922501670799125\n",
      "ребёнок: 1.2569724232415247\n",
      "боль: 1.2177990182137923\n",
      "\n",
      "Класс: travel\n",
      "мочь: 4.588684442883709\n",
      "место: 3.7816484283100524\n",
      "страна: 2.377382023676275\n",
      "путешественник: 2.2786440077641545\n",
      "часто: 2.276806673448208\n",
      "являться: 2.257954884084439\n",
      "путешествие: 2.237478796363646\n",
      "поездка: 2.1374001892864154\n",
      "человек: 2.0975730770017402\n",
      "также: 2.084621712985984\n",
      "\n",
      "Класс: sports\n",
      "год: 2.547024738278007\n",
      "игра: 2.2759724526528995\n",
      "олимпийский: 2.0704445542393377\n",
      "матч: 2.047749194023902\n",
      "команда: 1.6803306055196674\n",
      "спорт: 1.61503656101149\n",
      "игрок: 1.6055276987765132\n",
      "гол: 1.5823985230258524\n",
      "также: 1.5337108567231923\n",
      "свой: 1.5194854405249154\n"
     ]
    }
   ],
   "source": [
    "#Рассчет TF-IDF\n",
    "tfidf_results = {}\n",
    "\n",
    "classes = train_df['category'].unique()  \n",
    "\n",
    "for cls in classes:\n",
    "    texts = train_df[train_df['category'] == cls]['clean_text']\n",
    "    \n",
    "    # Рассчет TF-IDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_tfidf = tfidf.fit_transform(texts).toarray()\n",
    "    \n",
    "    # Получаем слова \n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    \n",
    "    tfidf_scores = X_tfidf.sum(axis=0)  # Суммируем TF-IDF \n",
    "    tfidf_results[cls] = {feature_names[i]: tfidf_scores[i] for i in range(len(feature_names))}\n",
    "\n",
    "for cls, scores in tfidf_results.items():\n",
    "    print(f\"\\nКласс: {cls}\")\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for word, score in sorted_scores[:10]:  # Выводим топ-10 слов по TF-IDF\n",
    "        print(f\"{word}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6be72406-6a17-44d4-89a4-77a931526a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "labels = open('dataset/data_rus_Cyrl_labels.txt').read().splitlines()\n",
    "label_encoder = {'geography': 0, 'science/technology': 1, 'entertainment': 2, 'politics': 3, 'health': 4, 'travel': 5, 'sports': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "708d2e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.75      0.16      0.26        19\n",
      "            travel       0.80      0.24      0.36        17\n",
      "          politics       0.75      0.14      0.23        22\n",
      "            sports       0.68      0.57      0.62        30\n",
      "            health       0.49      0.86      0.63        51\n",
      "     entertainment       0.69      0.44      0.54        25\n",
      "         geography       0.49      0.75      0.59        40\n",
      "\n",
      "          accuracy                           0.55       204\n",
      "         macro avg       0.66      0.45      0.46       204\n",
      "      weighted avg       0.62      0.55      0.51       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MultinomialNB\n",
    "Датасет без обработки\n",
    "'''\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4fa009b-50bb-4c35-acae-1da9720f929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.60      0.16      0.25        19\n",
      "            travel       0.62      0.29      0.40        17\n",
      "          politics       0.69      0.41      0.51        22\n",
      "            sports       0.62      0.43      0.51        30\n",
      "            health       0.42      0.69      0.52        51\n",
      "     entertainment       0.65      0.44      0.52        25\n",
      "         geography       0.44      0.62      0.52        40\n",
      "\n",
      "          accuracy                           0.50       204\n",
      "         macro avg       0.58      0.44      0.46       204\n",
      "      weighted avg       0.54      0.50      0.48       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MultinomialNB\n",
    "pymorphy2\n",
    "'''\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2330ea2e-e61a-48f6-9920-9b4034dc1eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        19\n",
      "            travel       0.00      0.00      0.00        17\n",
      "          politics       1.00      0.09      0.17        22\n",
      "            sports       0.67      0.13      0.22        30\n",
      "            health       0.30      0.84      0.44        51\n",
      "     entertainment       1.00      0.20      0.33        25\n",
      "         geography       0.46      0.53      0.49        40\n",
      "\n",
      "          accuracy                           0.37       204\n",
      "         macro avg       0.49      0.26      0.24       204\n",
      "      weighted avg       0.49      0.37      0.30       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MultinomialNB\n",
    "tfidf\n",
    "'''\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6030ddfb-ec0c-47b3-8254-e7f7c6192129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментация\n",
    "\n",
    "aug = SynonymAug(aug_src='wordnet')\n",
    "augmented_texts = [aug.augment(text) for text in train_df['text']]  \n",
    "train_df_augmented = pd.concat([train_df, pd.DataFrame({'text': augmented_texts, 'category': train_df['category']})]) \n",
    "train_df_augmented['text'] = train_df_augmented['text'].apply(' '.join)\n",
    "\n",
    "train_df_augmented['clean_text'] = train_df_augmented['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "864e3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.75      0.16      0.26        19\n",
      "            travel       0.80      0.24      0.36        17\n",
      "          politics       0.75      0.14      0.23        22\n",
      "            sports       0.65      0.57      0.61        30\n",
      "            health       0.49      0.84      0.62        51\n",
      "     entertainment       0.73      0.44      0.55        25\n",
      "         geography       0.48      0.75      0.59        40\n",
      "\n",
      "          accuracy                           0.54       204\n",
      "         macro avg       0.67      0.45      0.46       204\n",
      "      weighted avg       0.62      0.54      0.51       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MultinomialNB\n",
    "Аугментация\n",
    "'''\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train_augmented = vectorizer.fit_transform(train_df_augmented['text']) \n",
    "y_train = train_df_augmented['category']\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_augmented, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9edfb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        19\n",
      "            travel       0.00      0.00      0.00        17\n",
      "          politics       0.00      0.00      0.00        22\n",
      "            sports       0.00      0.00      0.00        30\n",
      "            health       0.25      1.00      0.40        51\n",
      "     entertainment       0.00      0.00      0.00        25\n",
      "         geography       0.00      0.00      0.00        40\n",
      "\n",
      "          accuracy                           0.25       204\n",
      "         macro avg       0.04      0.14      0.06       204\n",
      "      weighted avg       0.06      0.25      0.10       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MultinomialNB\n",
    "PCA\n",
    "'''\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "nmf = NMF(n_components=100, max_iter=1000)\n",
    "\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "X_train_nmf = nmf.fit_transform(X_train_tfidf) # PCA генерирует отрицательные значения\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_nmf = nmf.transform(X_test_tfidf)\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_nmf, y_train)\n",
    "y_pred = model.predict(X_test_nmf)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0941a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.67      0.11      0.18        19\n",
      "            travel       0.86      0.35      0.50        17\n",
      "          politics       0.25      0.05      0.08        22\n",
      "            sports       0.67      0.53      0.59        30\n",
      "            health       0.45      0.75      0.56        51\n",
      "     entertainment       0.55      0.48      0.51        25\n",
      "         geography       0.50      0.75      0.60        40\n",
      "\n",
      "          accuracy                           0.51       204\n",
      "         macro avg       0.56      0.43      0.43       204\n",
      "      weighted avg       0.54      0.51      0.48       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "логистическая регрессия\n",
    "Датасет без обработки\n",
    "'''\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e4ac382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       1.00      0.11      0.19        19\n",
      "            travel       0.67      0.24      0.35        17\n",
      "          politics       0.67      0.18      0.29        22\n",
      "            sports       0.86      0.20      0.32        30\n",
      "            health       0.29      0.90      0.44        51\n",
      "     entertainment       0.88      0.28      0.42        25\n",
      "         geography       0.50      0.20      0.29        40\n",
      "\n",
      "          accuracy                           0.38       204\n",
      "         macro avg       0.69      0.30      0.33       204\n",
      "      weighted avg       0.62      0.38      0.34       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "логистическая регрессия\n",
    "pymorphy2\n",
    "'''\n",
    "model = LogisticRegression()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1db350b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        19\n",
      "            travel       1.00      0.06      0.11        17\n",
      "          politics       0.75      0.14      0.23        22\n",
      "            sports       0.86      0.20      0.32        30\n",
      "            health       0.28      0.90      0.43        51\n",
      "     entertainment       1.00      0.24      0.39        25\n",
      "         geography       0.46      0.28      0.34        40\n",
      "\n",
      "          accuracy                           0.36       204\n",
      "         macro avg       0.62      0.26      0.26       204\n",
      "      weighted avg       0.57      0.36      0.30       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "логистическая регрессия\n",
    "tfidf\n",
    "'''\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54f352a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.67      0.11      0.18        19\n",
      "            travel       0.86      0.35      0.50        17\n",
      "          politics       0.25      0.05      0.08        22\n",
      "            sports       0.65      0.50      0.57        30\n",
      "            health       0.47      0.75      0.58        51\n",
      "     entertainment       0.60      0.48      0.53        25\n",
      "         geography       0.46      0.78      0.58        40\n",
      "\n",
      "          accuracy                           0.51       204\n",
      "         macro avg       0.57      0.43      0.43       204\n",
      "      weighted avg       0.54      0.51      0.47       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "логистическая регрессия\n",
    "Аугментация\n",
    "'''\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "X_train_augmented = vectorizer.fit_transform(train_df_augmented['text']) \n",
    "y_train = train_df_augmented['category']\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_augmented, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae71116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        19\n",
      "            travel       0.00      0.00      0.00        17\n",
      "          politics       1.00      0.09      0.17        22\n",
      "            sports       0.86      0.20      0.32        30\n",
      "            health       0.27      0.86      0.41        51\n",
      "     entertainment       1.00      0.24      0.39        25\n",
      "         geography       0.46      0.30      0.36        40\n",
      "\n",
      "          accuracy                           0.34       204\n",
      "         macro avg       0.51      0.24      0.24       204\n",
      "      weighted avg       0.51      0.34      0.29       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "логистическая регрессия\n",
    "PCA\n",
    "'''\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "y_test = test_df['category']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "77f69470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.20      0.11      0.14        19\n",
      "            travel       0.25      0.18      0.21        17\n",
      "          politics       0.22      0.18      0.20        22\n",
      "            sports       0.69      0.30      0.42        30\n",
      "            health       0.33      0.49      0.39        51\n",
      "     entertainment       0.39      0.36      0.38        25\n",
      "         geography       0.35      0.45      0.39        40\n",
      "\n",
      "          accuracy                           0.34       204\n",
      "         macro avg       0.35      0.29      0.30       204\n",
      "      weighted avg       0.36      0.34      0.33       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Дерево решений\n",
    "Датасет без обработки\n",
    "'''\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c27cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.38      0.16      0.22        19\n",
      "            travel       0.80      0.24      0.36        17\n",
      "          politics       0.56      0.23      0.32        22\n",
      "            sports       0.71      0.17      0.27        30\n",
      "            health       0.28      0.90      0.43        51\n",
      "     entertainment       0.60      0.12      0.20        25\n",
      "         geography       0.62      0.12      0.21        40\n",
      "\n",
      "          accuracy                           0.35       204\n",
      "         macro avg       0.56      0.28      0.29       204\n",
      "      weighted avg       0.53      0.35      0.30       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Дерево решений\n",
    "pymorphy2\n",
    "'''\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61d042ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.50      0.16      0.24        19\n",
      "            travel       0.67      0.24      0.35        17\n",
      "          politics       0.71      0.23      0.34        22\n",
      "            sports       0.50      0.17      0.25        30\n",
      "            health       0.27      0.82      0.41        51\n",
      "     entertainment       0.50      0.16      0.24        25\n",
      "         geography       0.62      0.20      0.30        40\n",
      "\n",
      "          accuracy                           0.35       204\n",
      "         macro avg       0.54      0.28      0.31       204\n",
      "      weighted avg       0.50      0.35      0.32       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Дерево решений\n",
    "tfidf\n",
    "'''\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "89be7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.30      0.16      0.21        19\n",
      "            travel       0.26      0.29      0.28        17\n",
      "          politics       0.13      0.14      0.13        22\n",
      "            sports       0.52      0.37      0.43        30\n",
      "            health       0.30      0.35      0.32        51\n",
      "     entertainment       0.42      0.40      0.41        25\n",
      "         geography       0.35      0.40      0.37        40\n",
      "\n",
      "          accuracy                           0.32       204\n",
      "         macro avg       0.33      0.30      0.31       204\n",
      "      weighted avg       0.33      0.32      0.32       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Дерево решений\n",
    "Аугментация\n",
    "'''\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train_augmented = vectorizer.fit_transform(train_df_augmented['text']) \n",
    "y_train = train_df_augmented['category']\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category']\n",
    "\n",
    "model.fit(X_train_augmented, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b42a9935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        19\n",
      "            travel       0.00      0.00      0.00        17\n",
      "          politics       1.00      0.05      0.09        22\n",
      "            sports       0.75      0.20      0.32        30\n",
      "            health       0.26      0.86      0.40        51\n",
      "     entertainment       1.00      0.16      0.28        25\n",
      "         geography       0.45      0.23      0.30        40\n",
      "\n",
      "          accuracy                           0.31       204\n",
      "         macro avg       0.49      0.21      0.20       204\n",
      "      weighted avg       0.49      0.31      0.25       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Дерево решений\n",
    "PCA\n",
    "'''\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "y_train = train_df['category']\n",
    "\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "y_test = test_df['category']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9b1bde80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.31      0.24      0.27        17\n",
      "            travel       0.39      0.53      0.45        51\n",
      "          politics       0.25      0.21      0.23        19\n",
      "            sports       0.50      0.43      0.46        30\n",
      "            health       0.20      0.09      0.12        22\n",
      "     entertainment       0.49      0.60      0.54        40\n",
      "         geography       0.55      0.44      0.49        25\n",
      "\n",
      "          accuracy                           0.42       204\n",
      "         macro avg       0.38      0.36      0.37       204\n",
      "      weighted avg       0.40      0.42      0.40       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBClassifier\n",
    "Датасет без обработки\n",
    "'''\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['category'].map(label_encoder)\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category'].map(label_encoder)\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3fe0c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       1.00      0.18      0.30        17\n",
      "            travel       0.30      0.82      0.44        51\n",
      "          politics       0.46      0.32      0.38        19\n",
      "            sports       0.60      0.20      0.30        30\n",
      "            health       0.33      0.14      0.19        22\n",
      "     entertainment       0.53      0.25      0.34        40\n",
      "         geography       0.50      0.24      0.32        25\n",
      "\n",
      "          accuracy                           0.37       204\n",
      "         macro avg       0.53      0.31      0.33       204\n",
      "      weighted avg       0.49      0.37      0.34       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBClassifier\n",
    "pymorphy2\n",
    "'''\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category'].map(label_encoder)\n",
    "\n",
    "X_test_bow = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category'].map(label_encoder)\n",
    "\n",
    "model.fit(X_train_bow, y_train)\n",
    "y_pred = model.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7c58e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       1.00      0.06      0.11        17\n",
      "            travel       0.26      0.80      0.39        51\n",
      "          politics       0.38      0.26      0.31        19\n",
      "            sports       0.56      0.17      0.26        30\n",
      "            health       0.38      0.14      0.20        22\n",
      "     entertainment       0.33      0.07      0.12        40\n",
      "         geography       0.83      0.20      0.32        25\n",
      "\n",
      "          accuracy                           0.31       204\n",
      "         macro avg       0.53      0.24      0.25       204\n",
      "      weighted avg       0.47      0.31      0.26       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBClassifier\n",
    "tfidf\n",
    "'''\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "y_train = train_df['category'].map(label_encoder)\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "y_test = test_df['category'].map(label_encoder)\n",
    "\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "afe0790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.36      0.29      0.32        17\n",
      "            travel       0.37      0.49      0.42        51\n",
      "          politics       0.31      0.26      0.29        19\n",
      "            sports       0.50      0.33      0.40        30\n",
      "            health       0.14      0.09      0.11        22\n",
      "     entertainment       0.46      0.60      0.52        40\n",
      "         geography       0.43      0.36      0.39        25\n",
      "\n",
      "          accuracy                           0.39       204\n",
      "         macro avg       0.37      0.35      0.35       204\n",
      "      weighted avg       0.38      0.39      0.38       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBClassifier\n",
    "Аугментация\n",
    "'''\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "X_train_augmented = vectorizer.fit_transform(train_df_augmented['text']) \n",
    "y_train = train_df_augmented['category'].map(label_encoder)\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['category'].map(label_encoder)\n",
    "\n",
    "model.fit(X_train_augmented, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "659a9ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "science/technology       0.00      0.00      0.00        17\n",
      "            travel       0.26      0.82      0.39        51\n",
      "          politics       0.00      0.00      0.00        19\n",
      "            sports       0.86      0.20      0.32        30\n",
      "            health       1.00      0.09      0.17        22\n",
      "     entertainment       0.41      0.28      0.33        40\n",
      "         geography       1.00      0.20      0.33        25\n",
      "\n",
      "          accuracy                           0.32       204\n",
      "         macro avg       0.50      0.23      0.22       204\n",
      "      weighted avg       0.50      0.32      0.27       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBClassifier\n",
    "PCA\n",
    "'''\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "X_test_tfidf = tfidf.transform(test_df['text'])\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "y_train = train_df['category'].map(label_encoder)\n",
    "\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "y_test = test_df['category'].map(label_encoder)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=labels, zero_division=0)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
